{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Recommender Program Using Unsupervised Learning through the K-Nearest Neighbors Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run these commands in the terminal to install the needed packages:\n",
    "\n",
    "pip install pandas\n",
    "\n",
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    " \n",
    "# scikit-learn imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, our steps that we'll take are as follows:\n",
    "\n",
    "1. Read in the dataset and convert it to a pandas dataframe.\n",
    "\n",
    "2. Explore the dataset by looking at its dimensions, what columns it has, etc.\n",
    "\n",
    "3. Clean the dataset by getting rid of any duplicates, missing values, and unneeded columns.\n",
    "\n",
    "4. Convert categorical data into numerical data that can be used for our algorithm.\n",
    "\n",
    "5. Scale the data to minimize biases.\n",
    "\n",
    "6. Create the KNN model and ask the user for an input track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv file and create a dataframe\n",
    "tracks = pd.read_csv('dataset.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the first 5 rows\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out dimensions of df (rows, columns)\n",
    "tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the columns to see what attributes each track has\n",
    "tracks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, the quality of our machine learning model is heavily reliant on our dataset. Therefore, we need to make sure that our dataset is clean in order to produce high-quality results. This includes dealing with missing/NULL values, duplicate data, and irrelevant data in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out if we have any duplicates in our dataset. Looks like there's not!\n",
    "tracks.duplicated()\n",
    "\n",
    "# see if there's missing data in any of the columns\n",
    "tracks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the columns into categorical and numerical data\n",
    "\n",
    "# categorical columns\n",
    "cat_col = [col for col in tracks.columns if tracks[col].dtype == 'object']\n",
    "print('Categorical columns :',cat_col)\n",
    "# numerical columns\n",
    "num_col = [col for col in tracks.columns if tracks[col].dtype != 'object']\n",
    "print('Numerical columns :',num_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that there are some rows with the same track ID. This means that we have duplicate songs!\n",
    "tracks[cat_col].nunique()\n",
    "\n",
    "# TODO: get rid of the duplicates and make sure that there are none left\n",
    "\n",
    "# unique_tracks = tracks.drop_duplicates().reset_index(drop=True)\n",
    "# duplicates = unique_tracks['track_id'].duplicated()\n",
    "print(\"Rows with duplicates in 'track_id' column:\")\n",
    "(unique_tracks[duplicates])['track_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have some duplicates because some songs are remixes, so they have different track IDs. Thus, it makes it harder to find these remixes and get rid of them. You could probably utilize regex's to do this, but for the purposes of this workshop, we'll just leave in the remixes. They shouldn't affect the model that much since there are over 100,000 songs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a feature that we aren't interested in\n",
    "unique_tracks = unique_tracks.drop(['track_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for our machine learning algorithm to work, we'll need each categorical variable to be converted into real numbers. We can do this by using label encoding, which assigns each unique genre a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the unique genres\n",
    "\n",
    "# unique_genres = unique_tracks[\"track_genre\"].unique()\n",
    "# print(unique_genres)\n",
    "\n",
    "# fit and transform the 'track_genre' column to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "unique_tracks['track_genre'] = label_encoder.fit_transform(unique_tracks['track_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the dataframe with the encoded genre\n",
    "unique_tracks[\"track_genre\"].unique()\n",
    "non_unique_rows = unique_tracks[unique_tracks.duplicated(keep=False)]\n",
    "non_unique_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also get rid of songs with duplicate track names\n",
    "\n",
    "# TODO: drop rows that have duplicate track names\n",
    "\n",
    "# unique_tracks = unique_tracks.drop_duplicates(subset=['track_name'], keep='first').reset_index(drop=True)\n",
    "# non_unique_rows = unique_tracks[unique_tracks.duplicated(keep=False)]\n",
    "\n",
    "print(len(non_unique_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before with the 'track_genre' feature, we have another feature, the 'explicit' feature, which represents a boolean that is True if the song is explicit and False if not. Here, we can use one-hot encoding to convert each value to a 0 or a 1 to work with our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: utilize one-hot encoding to convert the 'explicit' feature into a binary format\n",
    "\n",
    "# unique_tracks['explicit'] = unique_tracks['explicit'].astype(int)\n",
    "# print(unique_tracks['explicit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_columns():\n",
    "    '''In this function, we'll be scaling the data by standardizing it, making sure that it's a dataframe,\n",
    "    printing its head and shape, and then returning the scaled dataframe.'''\n",
    "    \n",
    "    # TODO: create a StandardScaler() object, fit the scaler to the numerical data and transform the data, \n",
    "    # convert to dataframe\n",
    "    # scaler = StandardScaler()\n",
    "\n",
    "    # # fit the scaler to the data and transform it\n",
    "    # scaled_data = scaler.fit_transform(unique_tracks.drop(columns=['album_name', 'track_name', 'artists']))\n",
    "    # scaled_df = pd.DataFrame(scaled_data, columns=unique_tracks.columns.drop(['album_name', 'track_name', 'artists']))\n",
    "\n",
    "    scaled_df.head()\n",
    "    scaled_df.shape\n",
    "    return scaled_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_knn(scaled_df):\n",
    "    '''Initializes the K-Nearest Neighbors model and fits it on the given scaled dataframe.'''\n",
    "    \n",
    "    # TODO: create the model, letting k = 10 and the distance formula be 'euclidean'. Then, fit it to the data\n",
    "    # knn = NearestNeighbors(n_neighbors=10, metric='euclidean')\n",
    "    # knn.fit(scaled_df)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(track, knn, scaled_data):\n",
    "    '''Given an input track, checks if the track is in the dataset. If so, it retrieves the row number of its first\n",
    "    appearance and uses the K-Nearest Neighbors model to find the 10 nearest neighbors. Then, it prints the 10 tracks\n",
    "    and corresponding artists.'''\n",
    "    \n",
    "\n",
    "    if track not in unique_tracks['track_name'].values:\n",
    "        print(\"Track not in dataset\")\n",
    "    else:\n",
    "        # TODO: find the index of the track in the dataframe, then find the indices of the 10 closest tracks\n",
    "        # row_index = unique_tracks[unique_tracks['track_name'] == track].index[0]\n",
    "        # (unique_tracks.iloc[row_index]\n",
    "        \n",
    "        # distances, indices = knn.kneighbors(scaled_data.iloc[row_index].values.reshape(1, -1))\n",
    "\n",
    "        ret_tracks = []\n",
    "        # TODO: for each of the 10 closest tracks, append the 'track_name' and 'artists' features to the list\n",
    "        # for i in indices:\n",
    "        #     ret_tracks.append((unique_tracks.iloc[i]['track_name'], unique_tracks.iloc[i]['artists']))\n",
    "        print(ret_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call our functions and ask the user to input a track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scale_columns()\n",
    "knn = setup_knn(scaled_data)\n",
    "input_track = input(\"Enter a track: \")\n",
    "recommend_songs(input_track, knn, scaled_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
