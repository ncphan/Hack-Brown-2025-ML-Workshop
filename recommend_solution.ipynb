{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Recommender Program Using Unsupervised Learning through the K-Nearest Neighbors Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll want to create a virtual environment in Python. We want to do this because virtual environments essentially give you a way to isolate your dependencies from other Python programs. Essentially, since we'll be installing and using Python packages in this demo, we don't want these packages to interfere with any other Python programs that you may have, so we'll just create our own virtual environment for this. Run the two commands below in the terminal to setup a virtual environment.\n",
    "\n",
    "-   python3 -m venv myenv\n",
    "\n",
    "-   source myenv/bin/activate\n",
    "\n",
    "Then, install pandas and scikit-learn (which are packages that we'll be using) by running the two commands below and wait for it to download.\n",
    "\n",
    "-   pip install pandas\n",
    "\n",
    "-   pip install scikit-learn\n",
    "\n",
    "After that, you may need to select a kernel. Do this by clicking the 'kernel' button in the top-right and setting it to your virtual environment. You may need to install ipykernel to do this, which you should do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    " \n",
    "# scikit-learn imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, our steps that we'll take are as follows:\n",
    "\n",
    "1. Read in the dataset and convert it to a pandas dataframe.\n",
    "\n",
    "2. Explore the dataset by looking at its dimensions, what columns it has, etc.\n",
    "\n",
    "3. Clean the dataset by getting rid of any duplicates, missing values, and unneeded columns.\n",
    "\n",
    "4. Convert categorical data into numerical data that can be used for our algorithm.\n",
    "\n",
    "5. Scale the data to minimize biases.\n",
    "\n",
    "6. Create the KNN model and ask the user for an input track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was taken from Kaggle at https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset. It contains data for over 100,000 tracks across over 125 different genres. It was last updated 2 years ago, so the program won't be able to accept songs released after then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv file and create a dataframe\n",
    "tracks = pd.read_csv('dataset.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been written to output.csv\n"
     ]
    }
   ],
   "source": [
    "# print out the first 5 rows\n",
    "tracks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114000, 21)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out dimensions of df (rows, columns)\n",
    "tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name',\n",
       "       'popularity', 'duration_ms', 'explicit', 'danceability', 'energy',\n",
       "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
       "       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature',\n",
       "       'track_genre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the columns to see what attributes each track has\n",
    "tracks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, the quality of our machine learning model is heavily reliant on our dataset. Therefore, we need to make sure that our dataset is clean in order to produce high-quality results. This includes dealing with missing/NULL values, duplicate data, and irrelevant data in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114000 entries, 0 to 113999\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Unnamed: 0        114000 non-null  int64  \n",
      " 1   track_id          114000 non-null  object \n",
      " 2   artists           113999 non-null  object \n",
      " 3   album_name        113999 non-null  object \n",
      " 4   track_name        113999 non-null  object \n",
      " 5   popularity        114000 non-null  int64  \n",
      " 6   duration_ms       114000 non-null  int64  \n",
      " 7   explicit          114000 non-null  bool   \n",
      " 8   danceability      114000 non-null  float64\n",
      " 9   energy            114000 non-null  float64\n",
      " 10  key               114000 non-null  int64  \n",
      " 11  loudness          114000 non-null  float64\n",
      " 12  mode              114000 non-null  int64  \n",
      " 13  speechiness       114000 non-null  float64\n",
      " 14  acousticness      114000 non-null  float64\n",
      " 15  instrumentalness  114000 non-null  float64\n",
      " 16  liveness          114000 non-null  float64\n",
      " 17  valence           114000 non-null  float64\n",
      " 18  tempo             114000 non-null  float64\n",
      " 19  time_signature    114000 non-null  int64  \n",
      " 20  track_genre       114000 non-null  object \n",
      "dtypes: bool(1), float64(9), int64(6), object(5)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# print out if we have any duplicates in our dataset. Looks like there's not!\n",
    "tracks.duplicated()\n",
    "\n",
    "# see if there's missing data in any of the columns\n",
    "tracks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns : ['track_id', 'artists', 'album_name', 'track_name', 'track_genre']\n",
      "Numerical columns : ['Unnamed: 0', 'popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n"
     ]
    }
   ],
   "source": [
    "# filter the columns into categorical and numerical data\n",
    "\n",
    "# categorical columns\n",
    "cat_col = [col for col in tracks.columns if tracks[col].dtype == 'object']\n",
    "print('Categorical columns :',cat_col)\n",
    "# numerical columns\n",
    "num_col = [col for col in tracks.columns if tracks[col].dtype != 'object']\n",
    "print('Numerical columns :',num_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with duplicates in 'track_id' column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1925                   Song for Rollins\n",
       "2155                      Snow (Hey Oh)\n",
       "3000                       Daddy Issues\n",
       "3002                           Softcore\n",
       "3003                    Sweater Weather\n",
       "                      ...              \n",
       "113572         Jesus We Love You - Live\n",
       "113605    In The Ordinary - Spontaneous\n",
       "113617                 King of My Heart\n",
       "113619                           Simple\n",
       "113641                           Closer\n",
       "Name: track_name, Length: 24259, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we see that there are some rows with the same track ID. This means that we have duplicate songs!\n",
    "tracks[cat_col].nunique()\n",
    "\n",
    "unique_tracks = tracks.drop_duplicates().reset_index(drop=True)\n",
    "duplicates = unique_tracks['track_id'].duplicated()\n",
    "\n",
    "print(\"Rows with duplicates in 'track_id' column:\")\n",
    "(unique_tracks[duplicates])['track_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have some duplicates because some songs are remixes, so they have different track IDs. Thus, it makes it harder to find these remixes and get rid of them. You could probably utilize regex's to do this, but for the purposes of this workshop, we'll just leave in the remixes. They shouldn't affect the model that much since there are over 100,000 songs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a feature that we aren't interested in\n",
    "unique_tracks = unique_tracks.drop(['track_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for our machine learning algorithm to work, we'll need each categorical variable to be converted into real numbers. We can do this by using label encoding, which assigns each unique genre a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acoustic' 'afrobeat' 'alt-rock' 'alternative' 'ambient' 'anime'\n",
      " 'black-metal' 'bluegrass' 'blues' 'brazil' 'breakbeat' 'british'\n",
      " 'cantopop' 'chicago-house' 'children' 'chill' 'classical' 'club' 'comedy'\n",
      " 'country' 'dance' 'dancehall' 'death-metal' 'deep-house' 'detroit-techno'\n",
      " 'disco' 'disney' 'drum-and-bass' 'dub' 'dubstep' 'edm' 'electro'\n",
      " 'electronic' 'emo' 'folk' 'forro' 'french' 'funk' 'garage' 'german'\n",
      " 'gospel' 'goth' 'grindcore' 'groove' 'grunge' 'guitar' 'happy'\n",
      " 'hard-rock' 'hardcore' 'hardstyle' 'heavy-metal' 'hip-hop' 'honky-tonk'\n",
      " 'house' 'idm' 'indian' 'indie-pop' 'indie' 'industrial' 'iranian'\n",
      " 'j-dance' 'j-idol' 'j-pop' 'j-rock' 'jazz' 'k-pop' 'kids' 'latin'\n",
      " 'latino' 'malay' 'mandopop' 'metal' 'metalcore' 'minimal-techno' 'mpb'\n",
      " 'new-age' 'opera' 'pagode' 'party' 'piano' 'pop-film' 'pop' 'power-pop'\n",
      " 'progressive-house' 'psych-rock' 'punk-rock' 'punk' 'r-n-b' 'reggae'\n",
      " 'reggaeton' 'rock-n-roll' 'rock' 'rockabilly' 'romance' 'sad' 'salsa'\n",
      " 'samba' 'sertanejo' 'show-tunes' 'singer-songwriter' 'ska' 'sleep'\n",
      " 'songwriter' 'soul' 'spanish' 'study' 'swedish' 'synth-pop' 'tango'\n",
      " 'techno' 'trance' 'trip-hop' 'turkish' 'world-music']\n"
     ]
    }
   ],
   "source": [
    "# print the unique genres\n",
    "unique_genres = unique_tracks[\"track_genre\"].unique()\n",
    "print(unique_genres)\n",
    "\n",
    "# create a LabelEncoder() and then use it to fit and transform the 'track_genre' data\n",
    "label_encoder = LabelEncoder()\n",
    "unique_tracks['track_genre'] = label_encoder.fit_transform(unique_tracks['track_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, artists, album_name, track_name, popularity, duration_ms, explicit, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time_signature, track_genre]\n",
       "Index: []"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the dataframe with the encoded genre\n",
    "unique_tracks[\"track_genre\"].unique()\n",
    "non_unique_rows = unique_tracks[unique_tracks.duplicated(keep=False)]\n",
    "non_unique_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# let's also get rid of songs with duplicate track names\n",
    "\n",
    "# TODO: drop rows that have duplicate track names\n",
    "\n",
    "unique_tracks = unique_tracks.drop_duplicates(subset=['track_name'], keep='first').reset_index(drop=True)\n",
    "non_unique_rows = unique_tracks[unique_tracks.duplicated(keep=False)]\n",
    "\n",
    "print(len(non_unique_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before with the 'track_genre' feature, we have another feature, the 'explicit' feature, which represents a boolean that is True if the song is explicit and False if not. Here, we can use one-hot encoding to convert each value to a 0 or a 1 to work with our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# TODO: utilize one-hot encoding to convert the 'explicit' feature into a binary format\n",
    "\n",
    "unique_tracks['explicit'] = unique_tracks['explicit'].astype(int)\n",
    "print(unique_tracks['explicit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_columns():\n",
    "    '''In this function, we'll be scaling the data by standardizing it, making sure that it's a dataframe,\n",
    "    printing its head and shape, and then returning the scaled dataframe.'''\n",
    "    \n",
    "    # TODO: create a StandardScaler() object, fit the scaler to the numerical data and transform the data, \n",
    "    # convert to dataframe\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # fit the scaler to the data and transform it\n",
    "    scaled_data = scaler.fit_transform(unique_tracks.drop(columns=['album_name', 'track_name', 'artists']))\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=unique_tracks.columns.drop(['album_name', 'track_name', 'artists']))\n",
    "\n",
    "    scaled_df.head()\n",
    "    scaled_df.shape\n",
    "    return scaled_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_knn(scaled_df):\n",
    "    '''Initializes the K-Nearest Neighbors model and fits it on the given scaled dataframe.'''\n",
    "    \n",
    "    # TODO: create the model, letting k = 10 and the distance formula be 'euclidean'. Then, fit it to the data\n",
    "    knn = NearestNeighbors(n_neighbors=10, metric='euclidean')\n",
    "    knn.fit(scaled_df)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(track, knn, scaled_data):\n",
    "    '''Given an input track, checks if the track is in the dataset. If so, it retrieves the row number of its first\n",
    "    appearance and uses the K-Nearest Neighbors model to find the 10 nearest neighbors. Then, it prints the 10 tracks\n",
    "    and corresponding artists.'''\n",
    "    \n",
    "\n",
    "    if track not in unique_tracks['track_name'].values:\n",
    "        print(\"Track not in dataset\")\n",
    "    else:\n",
    "        # TODO: find the index of the track in the dataframe, then find the indices of the 10 closest tracks\n",
    "        row_index = unique_tracks[unique_tracks['track_name'] == track].index[0]\n",
    "        unique_tracks.iloc[row_index]\n",
    "        \n",
    "        distances, indices = knn.kneighbors(scaled_data.iloc[row_index].values.reshape(1, -1))\n",
    "\n",
    "        ret_tracks = []\n",
    "        # TODO: for each of the 10 closest tracks, append the 'track_name' and 'artists' features to the list\n",
    "        for i in indices:\n",
    "            ret_tracks.append((unique_tracks.iloc[i]['track_name'], unique_tracks.iloc[i]['artists']))\n",
    "        print(ret_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call our functions and ask the user to input a track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9070                 Hello\n",
      "9102     Chasing Pavements\n",
      "9468     Keep Your Head Up\n",
      "16707         Good For You\n",
      "2686           Akuma no Ko\n",
      "2011      Carnival of Rust\n",
      "133             Had It All\n",
      "12804        Can't Pretend\n",
      "4509                  春はゆく\n",
      "2414                Heroes\n",
      "Name: track_name, dtype: object, 9070                       Adele\n",
      "9102                       Adele\n",
      "9468                  Ben Howard\n",
      "16707    Selena Gomez;A$AP Rocky\n",
      "2686                  Higuchi Ai\n",
      "2011           Poets of the Fall\n",
      "133                    Parachute\n",
      "12804                  Tom Odell\n",
      "4509                       Aimer\n",
      "2414                  Zayde Wølf\n",
      "Name: artists, dtype: object)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanphan/Desktop/python projects/workshop/myenv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaled_data = scale_columns()\n",
    "knn = setup_knn(scaled_data)\n",
    "input_track = input(\"Enter a track: \")\n",
    "recommend_songs(input_track, knn, scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you're done with running the project, feel free to deactivate your virtual environment by running the following command in the terminal:\n",
    "\n",
    "- deactivate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
