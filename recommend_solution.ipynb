{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Recommender Program Using Unsupervised Learning through the K-Nearest Neighbors Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll want to create a virtual environment in Python. We want to do this because virtual environments essentially give you a way to isolate your dependencies from other Python programs. Essentially, since we'll be installing and using Python packages in this demo, we don't want these packages to interfere with any other Python programs that you may have, so we'll just create our own virtual environment for this. Run the two commands below in the terminal to setup a virtual environment.\n",
    "\n",
    "-   python3 -m venv myenv\n",
    "\n",
    "-   source myenv/bin/activate\n",
    "\n",
    "Then, install pandas and scikit-learn (which are packages that we'll be using) by running the two commands below and wait for it to download.\n",
    "\n",
    "-   pip install pandas\n",
    "\n",
    "-   pip install scikit-learn\n",
    "\n",
    "After that, you may need to select a kernel. Do this by clicking the 'kernel' button in the top-right and setting it to your virtual environment. You may need to install ipykernel to do this, which you should do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    " \n",
    "# scikit-learn imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, our steps that we'll take are as follows:\n",
    "\n",
    "1. Read in the dataset and convert it to a pandas dataframe.\n",
    "\n",
    "2. Explore the dataset by looking at its dimensions, what columns it has, etc.\n",
    "\n",
    "3. Clean the dataset by getting rid of any duplicates, missing values, and unneeded columns.\n",
    "\n",
    "4. Convert categorical data into numerical data that can be used for our algorithm.\n",
    "\n",
    "5. Scale the data to minimize biases.\n",
    "\n",
    "6. Create the KNN model and ask the user for an input track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was taken from Kaggle at https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset. It contains data for over 100,000 tracks across over 125 different genres. It was last updated 2 years ago, so the program won't be able to accept songs released after then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv file and create a dataframe\n",
    "tracks = pd.read_csv('dataset.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                track_id                 artists  \\\n",
       "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666     False   \n",
       "1            Ghost - Acoustic          55       149610     False   \n",
       "2              To Begin Again          57       210826     False   \n",
       "3  Can't Help Falling In Love          71       201933     False   \n",
       "4                     Hold On          82       198853     False   \n",
       "\n",
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610    1    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660    1   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590    0    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596    0   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430    2    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4    acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4    acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4    acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3    acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4    acoustic  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the first 5 rows\n",
    "tracks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114000, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out dimensions of df (rows, columns)\n",
    "tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name',\n",
       "       'popularity', 'duration_ms', 'explicit', 'danceability', 'energy',\n",
       "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
       "       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature',\n",
       "       'track_genre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the columns to see what attributes each track has\n",
    "tracks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, the quality of our machine learning model is heavily reliant on our dataset. Therefore, we need to make sure that our dataset is clean in order to produce high-quality results. This includes dealing with missing/NULL values, duplicate data, and irrelevant data in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         False\n",
      "1         False\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "113995    False\n",
      "113996    False\n",
      "113997    False\n",
      "113998    False\n",
      "113999    False\n",
      "Length: 114000, dtype: bool\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114000 entries, 0 to 113999\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Unnamed: 0        114000 non-null  int64  \n",
      " 1   track_id          114000 non-null  object \n",
      " 2   artists           113999 non-null  object \n",
      " 3   album_name        113999 non-null  object \n",
      " 4   track_name        113999 non-null  object \n",
      " 5   popularity        114000 non-null  int64  \n",
      " 6   duration_ms       114000 non-null  int64  \n",
      " 7   explicit          114000 non-null  bool   \n",
      " 8   danceability      114000 non-null  float64\n",
      " 9   energy            114000 non-null  float64\n",
      " 10  key               114000 non-null  int64  \n",
      " 11  loudness          114000 non-null  float64\n",
      " 12  mode              114000 non-null  int64  \n",
      " 13  speechiness       114000 non-null  float64\n",
      " 14  acousticness      114000 non-null  float64\n",
      " 15  instrumentalness  114000 non-null  float64\n",
      " 16  liveness          114000 non-null  float64\n",
      " 17  valence           114000 non-null  float64\n",
      " 18  tempo             114000 non-null  float64\n",
      " 19  time_signature    114000 non-null  int64  \n",
      " 20  track_genre       114000 non-null  object \n",
      "dtypes: bool(1), float64(9), int64(6), object(5)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# print out if we have any duplicates in our dataset. Looks like there's not!\n",
    "print(tracks.duplicated())\n",
    "\n",
    "# see if there's missing data in any of the columns\n",
    "tracks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns : ['track_id', 'artists', 'album_name', 'track_name', 'track_genre']\n",
      "Numerical columns : ['Unnamed: 0', 'popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n"
     ]
    }
   ],
   "source": [
    "# filter the columns into categorical and numerical data\n",
    "\n",
    "# categorical columns\n",
    "cat_col = [col for col in tracks.columns if tracks[col].dtype == 'object']\n",
    "print('Categorical columns :',cat_col)\n",
    "# numerical columns\n",
    "num_col = [col for col in tracks.columns if tracks[col].dtype != 'object']\n",
    "print('Numerical columns :',num_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_id       89741\n",
      "artists        31437\n",
      "album_name     46589\n",
      "track_name     73608\n",
      "track_genre      114\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# we see that there are some rows with the same track ID. This means that we have duplicate songs!\n",
    "print(tracks[cat_col].nunique())\n",
    "\n",
    "unique_tracks = tracks.drop_duplicates().reset_index(drop=True)\n",
    "duplicates = unique_tracks['track_id'].duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have some duplicates because some songs are remixes, so they have different track IDs. Thus, it makes it harder to find these remixes and get rid of them. You could probably utilize regex's to do this, but for the purposes of this workshop, we'll just leave in the remixes. They shouldn't affect the model that much since there are over 100,000 songs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove a feature that we aren't interested in\n",
    "unique_tracks = unique_tracks.drop(['track_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for our machine learning algorithm to work, we'll need each categorical variable to be converted into real numbers. We can do this by using label encoding, which assigns each unique genre a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acoustic' 'afrobeat' 'alt-rock' 'alternative' 'ambient' 'anime'\n",
      " 'black-metal' 'bluegrass' 'blues' 'brazil' 'breakbeat' 'british'\n",
      " 'cantopop' 'chicago-house' 'children' 'chill' 'classical' 'club' 'comedy'\n",
      " 'country' 'dance' 'dancehall' 'death-metal' 'deep-house' 'detroit-techno'\n",
      " 'disco' 'disney' 'drum-and-bass' 'dub' 'dubstep' 'edm' 'electro'\n",
      " 'electronic' 'emo' 'folk' 'forro' 'french' 'funk' 'garage' 'german'\n",
      " 'gospel' 'goth' 'grindcore' 'groove' 'grunge' 'guitar' 'happy'\n",
      " 'hard-rock' 'hardcore' 'hardstyle' 'heavy-metal' 'hip-hop' 'honky-tonk'\n",
      " 'house' 'idm' 'indian' 'indie-pop' 'indie' 'industrial' 'iranian'\n",
      " 'j-dance' 'j-idol' 'j-pop' 'j-rock' 'jazz' 'k-pop' 'kids' 'latin'\n",
      " 'latino' 'malay' 'mandopop' 'metal' 'metalcore' 'minimal-techno' 'mpb'\n",
      " 'new-age' 'opera' 'pagode' 'party' 'piano' 'pop-film' 'pop' 'power-pop'\n",
      " 'progressive-house' 'psych-rock' 'punk-rock' 'punk' 'r-n-b' 'reggae'\n",
      " 'reggaeton' 'rock-n-roll' 'rock' 'rockabilly' 'romance' 'sad' 'salsa'\n",
      " 'samba' 'sertanejo' 'show-tunes' 'singer-songwriter' 'ska' 'sleep'\n",
      " 'songwriter' 'soul' 'spanish' 'study' 'swedish' 'synth-pop' 'tango'\n",
      " 'techno' 'trance' 'trip-hop' 'turkish' 'world-music']\n"
     ]
    }
   ],
   "source": [
    "# print the unique genres\n",
    "unique_genres = unique_tracks[\"track_genre\"].unique()\n",
    "print(unique_genres)\n",
    "\n",
    "# create a LabelEncoder() and then use it to fit and transform the 'track_genre' data\n",
    "label_encoder = LabelEncoder()\n",
    "unique_tracks['track_genre'] = label_encoder.fit_transform(unique_tracks['track_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, artists, album_name, track_name, popularity, duration_ms, explicit, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time_signature, track_genre]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the dataframe with the encoded genre\n",
    "unique_tracks[\"track_genre\"].unique()\n",
    "non_unique_rows = unique_tracks[unique_tracks.duplicated(keep=False)]\n",
    "non_unique_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# let's also get rid of songs with duplicate track names\n",
    "\n",
    "# TODO: drop rows that have duplicate track names\n",
    "\n",
    "unique_tracks = unique_tracks.drop_duplicates(subset=['track_name'], keep='first').reset_index(drop=True)\n",
    "non_unique_rows = unique_tracks[unique_tracks.duplicated(keep=False)]\n",
    "\n",
    "print(len(non_unique_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before with the 'track_genre' feature, we have another feature, the 'explicit' feature, which represents a boolean that is True if the song is explicit and False if not. Here, we can use one-hot encoding to convert each value to a 0 or a 1 to work with our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# TODO: utilize one-hot encoding to convert the 'explicit' feature into a binary format\n",
    "\n",
    "unique_tracks['explicit'] = unique_tracks['explicit'].astype(int)\n",
    "print(unique_tracks['explicit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_columns():\n",
    "    '''In this function, we'll be scaling the data by standardizing it, making sure that it's a dataframe,\n",
    "    printing its head and shape, and then returning the scaled dataframe.'''\n",
    "    \n",
    "    # TODO: create a StandardScaler() object, fit the scaler to the numerical data and transform the data, \n",
    "    # convert to dataframe\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # fit the scaler to the data and transform it\n",
    "    scaled_data = scaler.fit_transform(unique_tracks.drop(columns=['album_name', 'track_name', 'artists']))\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=unique_tracks.columns.drop(['album_name', 'track_name', 'artists']))\n",
    "\n",
    "    scaled_df.head()\n",
    "    scaled_df.shape\n",
    "    return scaled_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_knn(scaled_df):\n",
    "    '''Initializes the K-Nearest Neighbors model and fits it on the given scaled dataframe.'''\n",
    "    \n",
    "    # TODO: create the model, letting k = 10 and the distance formula be 'euclidean'. Then, fit it to the data\n",
    "    knn = NearestNeighbors(n_neighbors=10, metric='euclidean')\n",
    "    knn.fit(scaled_df)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_songs(track, knn, scaled_data):\n",
    "    '''Given an input track, checks if the track is in the dataset. If so, it retrieves the row number of its first\n",
    "    appearance and uses the K-Nearest Neighbors model to find the 10 nearest neighbors. Then, it prints the 10 tracks\n",
    "    and corresponding artists.'''\n",
    "    \n",
    "\n",
    "    if track not in unique_tracks['track_name'].values:\n",
    "        print(\"Track not in dataset\")\n",
    "    else:\n",
    "        # TODO: find the index of the track in the dataframe, then find the indices of the 10 closest tracks\n",
    "        row_index = unique_tracks[unique_tracks['track_name'] == track].index[0]\n",
    "        unique_tracks.iloc[row_index]\n",
    "        \n",
    "        distances, indices = knn.kneighbors(scaled_data.iloc[row_index].values.reshape(1, -1))\n",
    "\n",
    "        ret_tracks = []\n",
    "\n",
    "        for i in indices:\n",
    "            ret_tracks.append((unique_tracks.iloc[i]['track_name'], unique_tracks.iloc[i]['artists']))\n",
    "        print(ret_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call our functions and ask the user to input a track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(23828                                     Call Me Maybe\n",
      "18652                  Say Something - Zac Samuel Remix\n",
      "16469    Leave Before You Love Me (with Jonas Brothers)\n",
      "28284                                     Sweat - Remix\n",
      "16502                                   Cheating on You\n",
      "23334                                             Liggi\n",
      "27168                                 Ainsi bas la vida\n",
      "25763                                 Green Green Grass\n",
      "27412                                     Give It to Me\n",
      "20122     Hungry Eyes - From \"Dirty Dancing\" Soundtrack\n",
      "Name: track_name, dtype: object, 23828                                     Carly Rae Jepsen\n",
      "18652                             Karen Harding;Zac Samuel\n",
      "16469                            Marshmello;Jonas Brothers\n",
      "28284    Snoop Dogg;David Guetta;Giorgio Tuinfort;Frede...\n",
      "16502                                         Charlie Puth\n",
      "23334                                               Ritviz\n",
      "27168                                               Indila\n",
      "25763                                          George Ezra\n",
      "27412                                         Matt Sassari\n",
      "20122                                          Eric Carmen\n",
      "Name: artists, dtype: object)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanphan/Desktop/python projects/workshop/myenv/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaled_data = scale_columns()\n",
    "knn = setup_knn(scaled_data)\n",
    "input_track = input(\"Enter a track: \")\n",
    "recommend_songs(input_track, knn, scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you're done with running the project, feel free to deactivate your virtual environment by running the following command in the terminal:\n",
    "\n",
    "- deactivate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
